{"cells": [{"cell_type": "code", "execution_count": 1, "id": "954a9101-aec8-4800-92b2-8c3e39739e87", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/02/11 16:02:28 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n        .appName(\"Difference Group By and Reduce By Key\") \\\n        .master(\"yarn\") \\\n        .getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "a5a77877-4c88-460a-b090-aedad90d6b92", "metadata": {}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-f3f6-m.us-central1-f.c.still-smithy-449618-m7.internal:45309\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f2e473c6950>"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "spark"}, {"cell_type": "code", "execution_count": 3, "id": "c14c7756-37fb-4dcf-9208-26ddf3eb83c0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 5 items\n-rw-r--r--   2 lokesh hadoop    327.4 M 2025-02-10 16:01 /ecommerce_data/ecommerce_data/300MB/customers.csv\n-rw-r--r--   2 lokesh hadoop    275.3 M 2025-02-10 16:01 /ecommerce_data/ecommerce_data/300MB/items.csv\n-rw-r--r--   2 lokesh hadoop    271.0 M 2025-02-10 16:01 /ecommerce_data/ecommerce_data/300MB/orders.csv\n-rw-r--r--   2 lokesh hadoop    268.4 M 2025-02-10 16:01 /ecommerce_data/ecommerce_data/300MB/payments.csv\n-rw-r--r--   2 lokesh hadoop    256.5 M 2025-02-10 16:01 /ecommerce_data/ecommerce_data/300MB/shippings.csv\n"}], "source": "!hadoop fs -ls -h /ecommerce_data/ecommerce_data/300MB"}, {"cell_type": "code", "execution_count": 4, "id": "5b81d148-11bf-44c7-ba47-da9754ec1841", "metadata": {}, "outputs": [], "source": "hdfs_path = \"/ecommerce_data/ecommerce_data/300MB/customers.csv\""}, {"cell_type": "code", "execution_count": 5, "id": "93bf052c-f9a9-4353-a1d1-1c2f7e365abf", "metadata": {}, "outputs": [], "source": "customer_rdd = spark.sparkContext.textFile(hdfs_path)"}, {"cell_type": "code", "execution_count": 6, "id": "ef032e48-aa19-42b2-8853-2245ef6635f3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "header = customer_rdd.first()"}, {"cell_type": "code", "execution_count": 7, "id": "c12eac7a-493b-4c66-bea5-0c4f0ef3dcf0", "metadata": {}, "outputs": [], "source": "customer_rdd = customer_rdd.filter(lambda row : row != header)"}, {"cell_type": "code", "execution_count": 8, "id": "4eff889a-6be8-4d40-86f0-6969e2190b44", "metadata": {}, "outputs": [], "source": "customer_rdd = customer_rdd.map(lambda row : row.split(\",\"))"}, {"cell_type": "code", "execution_count": 9, "id": "7c672874-e713-4568-8d96-a00159bbf176", "metadata": {}, "outputs": [{"data": {"text/plain": "['0', 'Customer_0', 'Pune', 'Maharashtra', 'India', '2023-01-19', 'True']"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "customer_rdd.first()"}, {"cell_type": "code", "execution_count": 10, "id": "4ff97c2c-0867-4dd8-af8d-40b90f81818b", "metadata": {}, "outputs": [], "source": "city_rdd = customer_rdd.map(lambda row : (row[2], 1))"}, {"cell_type": "markdown", "id": "af4f90d9-157d-416a-8a42-7860db698779", "metadata": {}, "source": "### **Reduce By**"}, {"cell_type": "code", "execution_count": 11, "id": "267076eb-ed55-460c-ba46-5a577a3257e2", "metadata": {}, "outputs": [], "source": "reduced_rdd = city_rdd.reduceByKey(lambda x, y : x + y)"}, {"cell_type": "code", "execution_count": 12, "id": "4eab78db-dc39-431a-987e-acd5c60b3df7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "[('Delhi', 661025),\n ('Chennai', 660249),\n ('Kolkata', 660174),\n ('Bangalore', 661013),\n ('Pune', 660737),\n ('Ahmedabad', 660218),\n ('Mumbai', 661241),\n ('Hyderabad', 662281)]"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "reduced_rdd.collect()"}, {"cell_type": "markdown", "id": "f8bfbbbe-1e19-43cc-a1cf-5de429ab21f8", "metadata": {}, "source": "### **Group By Key**"}, {"cell_type": "code", "execution_count": 13, "id": "777e1a8b-4ebe-45fe-aaab-fe8a1408cff7", "metadata": {}, "outputs": [], "source": "grouped_rdd = city_rdd.groupByKey()"}, {"cell_type": "code", "execution_count": 14, "id": "d416082c-0085-46bf-a575-76d205402d0f", "metadata": {}, "outputs": [], "source": "grouped_result = grouped_rdd.map(lambda x : (x[0],len(x[1])))"}, {"cell_type": "code", "execution_count": 15, "id": "7cf492e3-a743-4225-a29d-16801f85c43f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "[('Delhi', 661025),\n ('Pune', 660737),\n ('Kolkata', 660174),\n ('Chennai', 660249),\n ('Bangalore', 661013),\n ('Mumbai', 661241),\n ('Ahmedabad', 660218),\n ('Hyderabad', 662281)]"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "grouped_result.collect()"}, {"cell_type": "code", "execution_count": 16, "id": "3286aba7-aa90-497d-b41a-8399904d90aa", "metadata": {}, "outputs": [], "source": "spark.stop()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}